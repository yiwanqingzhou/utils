{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_point_cloud(path):\n",
    "    \"\"\"\n",
    "    Description\n",
    "    -----------\n",
    "        read point cloud\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        path: str\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        o3d.geometry.PointCloud\n",
    "    \"\"\"\n",
    "    cloud = o3d.io.read_point_cloud(path)\n",
    "    return cloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyquaternion import Quaternion\n",
    "\n",
    "\n",
    "def matrix2rotation(matrix):\n",
    "    return matrix[:3, :3]\n",
    "\n",
    "\n",
    "def matrix2qua(matrix):\n",
    "    qua = Quaternion(matrix=matrix2rotation(matrix))\n",
    "    return qua\n",
    "\n",
    "\n",
    "def matrix2trans(matrix):\n",
    "    return np.array(matrix[:3, 3:].transpose())[0]\n",
    "\n",
    "\n",
    "def matrix2pose(matrix):\n",
    "    qua = matrix2qua(matrix)\n",
    "    translation = matrix2trans(matrix)\n",
    "    return np.hstack((translation, qua.elements))\n",
    "\n",
    "\n",
    "def quatrans2matrix(qua, trans):\n",
    "    rotaion_matrix = qua.rotation_matrix\n",
    "    trans_matrix = np.array([trans]).transpose()\n",
    "    tf_m = np.hstack((rotaion_matrix, trans_matrix))\n",
    "    m = np.mat([[0, 0, 0, 1]])\n",
    "    tf_m = np.vstack((tf_m, m))\n",
    "\n",
    "    return tf_m\n",
    "\n",
    "\n",
    "def pose2matrix(pose):\n",
    "    w, x, y, z = pose[3:]\n",
    "    qua = Quaternion(w=w, x=x, y=y, z=z)\n",
    "    trans = pose[:3]\n",
    "    return quatrans2matrix(qua, trans)\n",
    "\n",
    "\n",
    "def translation2matrix(trans):\n",
    "    qua = Quaternion(w=1, x=0, y=0, z=0)\n",
    "    return quatrans2matrix(qua, trans)\n",
    "\n",
    "\n",
    "def qua2matrix(qua):\n",
    "    trans = [0, 0, 0]\n",
    "    return quatrans2matrix(qua, trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on instancemethod in module open3d.open3d.visualization:\n",
      "\n",
      "add_geometry(...)\n",
      "    add_geometry(self, geometry, reset_bounding_box=True)\n",
      "    \n",
      "    Function to add geometry to the scene and create corresponding shaders\n",
      "    \n",
      "    Args:\n",
      "        geometry (open3d.geometry.Geometry): The ``Geometry`` object.\n",
      "        reset_bounding_box (bool, optional, default=True): Set to ``False`` to keep current viewpoint\n",
      "    \n",
      "    Returns:\n",
      "        bool\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(o3d.visualization.Visualizer.add_geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_picked_indices(pcd):\n",
    "    vis = o3d.visualization.VisualizerWithEditing()\n",
    "    vis.create_window(window_name=\"Resgistration: Pick Corresponding Points\")\n",
    "    vis.add_geometry(pcd)\n",
    "    vis.run()\n",
    "    vis.destroy_window()\n",
    "    return vis.get_picked_points()\n",
    "\n",
    "\n",
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    source_temp.transform(transformation)\n",
    "    \n",
    "    world_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(1)\n",
    "\n",
    "    o3d.visualization.draw_geometries(\n",
    "        [world_frame, source_temp, target], window_name=\"Registration Visualization\"\n",
    "    )\n",
    "    return source_temp + target\n",
    "\n",
    "\n",
    "# def icp(source, target, icp_threshold):\n",
    "#     print('Please press Shift and click the feature points in the same order, press Q to finish')\n",
    "#     picked_id_source = get_picked_indices(source)\n",
    "#     print('picked_id_source: ', picked_id_source)\n",
    "#     return picked_id\n",
    "        \n",
    "#     while True:\n",
    "        \n",
    "#         print('Please press Shift and click the feature points in the same order, press Q to finish')\n",
    "#         picked_id_source = get_picked_indices(source)\n",
    "#         print('picked_id_source: ', picked_id_source)\n",
    "        \n",
    "#         print('Please press Shift and click the feature points, press Q to finish')\n",
    "#         picked_id_target = get_picked_indices(target)\n",
    "#         print('picked_id_target: ', picked_id_target)\n",
    "\n",
    "#         if len(picked_id_source) != len(picked_id_target):\n",
    "#             print(\"The number of corresponding points are not the same, please re-pick\")\n",
    "#         else:\n",
    "#             break\n",
    "\n",
    "#     corr = np.zeros((len(picked_id_source), 2))\n",
    "#     corr[:, 0] = picked_id_source\n",
    "#     corr[:, 1] = picked_id_target\n",
    "\n",
    "#     p2p = o3d.registration.TransformationEstimationPointToPoint()\n",
    "#     trans_init = p2p.compute_transformation(\n",
    "#         source, target, o3d.utility.Vector2iVector(corr)\n",
    "#     )\n",
    "\n",
    "#     reg_p2p = o3d.registration.registration_icp(\n",
    "#         source,\n",
    "#         target,\n",
    "#         icp_threshold,\n",
    "#         trans_init,\n",
    "#         o3d.registration.TransformationEstimationPointToPoint(),\n",
    "#     )\n",
    "\n",
    "#     transform = reg_p2p.transformation\n",
    "#     print(\"Transformation Matrix: \\n{}\\n\".format(transform))\n",
    "\n",
    "#     final_cloud = draw_registration_result(\n",
    "#         source, target, transform)\n",
    "    \n",
    "#     return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mesh_model(path):\n",
    "    \"\"\"\n",
    "    Description\n",
    "    -----------\n",
    "        read mesh model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        path: str\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        o3d.geometry.TriangleMesh\n",
    "    \"\"\"\n",
    "    mesh = o3d.io.read_triangle_mesh(path)\n",
    "    return mesh\n",
    "\n",
    "def sample_mesh_to_cloud(mesh, sample_number=100000):\n",
    "    \"\"\"\n",
    "    Description\n",
    "    -----------\n",
    "        process the cabinet mesh model, sample it as point cloud\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        mesh: o3d.geometry.TriangleMesh\n",
    "        sample_number: int\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        o3d.geometry.PointCloud\n",
    "    \"\"\"\n",
    "    mesh.compute_vertex_normals()\n",
    "    pcd = mesh.sample_points_uniformly(number_of_points=sample_number)\n",
    "    pcd.paint_uniform_color([1, 0.706, 0])  # yellow\n",
    "    return pcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/bot/dev/projects_data/potala/potala_tote.STL\"\n",
    "# path = \"/home/bot/dev/dr_vision_lib/modules/vision_calibration/python/example/example_data/model/shelves_3.stl\"\n",
    "mesh = load_mesh_model(path)\n",
    "target = sample_mesh_to_cloud(mesh, 500000)\n",
    "target.scale(0.001, center=False)\n",
    "\n",
    "target.transform(pose2matrix([0,0,0,0.707,0.707,0,0]).A)\n",
    "\n",
    "# add sign on front\n",
    "add_sign = True\n",
    "if add_sign:\n",
    "    sign_on_front = o3d.geometry.TriangleMesh.create_box(width=0.01, height=0.01, depth=0.01)\n",
    "    sign_cloud = sample_mesh_to_cloud(sign_on_front, 1000)\n",
    "    sign_cloud.transform(pose2matrix([-0.5, 0, 0, 1, 0, 0, 0]).A)\n",
    "    target =  target + sign_cloud\n",
    "\n",
    "\n",
    "# target.transform(pose2matrix([2.98, 0.78, 0.07, 1, 0, 0, 0]).A)\n",
    "\n",
    "world_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(1)\n",
    "\n",
    "\n",
    "o3d.visualization.draw_geometries([world_frame, target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target1 = load_point_cloud(\"/home/bot/dev/projects_data/kandovan/cur/tfed_whole_model.pcd\")\n",
    "# target1.transform(pose2matrix([-0.32699, 1.63399, 0.47999 - 0.05, 1.0, -0.00208, -0.00061, -0.00204]).A)\n",
    "\n",
    "target2 = load_point_cloud(\"/home/bot/dev/projects_data/kandovan/cur/tfed_whole_model.pcd\")\n",
    "target2.transform(pose2matrix([-0.34432, 2.21692, 0.02316 - 0.05, 0.99999, 0.00350, -0.00059, 0.00312]).A)\n",
    "\n",
    "target3 = load_point_cloud(\"/home/bot/dev/projects_data/kandovan/cur/tfed_whole_model.pcd\")\n",
    "target3.transform(pose2matrix([0.32633, 1.62217, 0.02579 - 0.05, 0.99994, -0.00452, -0.00653, 0.00771]).A)\n",
    "\n",
    "target4 = load_point_cloud(\"/home/bot/dev/projects_data/kandovan/cur/tfed_whole_model.pcd\")\n",
    "target4.transform(pose2matrix([0.31851, 2.22215, -0.05292 - 0.05, 0.99996, 0.00366, -0.00501, 0.00609]).A)\n",
    "\n",
    "# target =  target1 + target2 + target3 + target4\n",
    "target = target2 + target3 + target4\n",
    "\n",
    "sign_on_front = o3d.geometry.TriangleMesh.create_box(width=0.01, height=0.01, depth=0.01)\n",
    "sign_cloud = sample_mesh_to_cloud(sign_on_front, 1000)\n",
    "sign_cloud.transform(pose2matrix([0, 1, 0, 1, 0, 0, 0]).A)\n",
    "target =  target + sign_cloud\n",
    "\n",
    "world_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(1)\n",
    "o3d.visualization.draw_geometries([world_frame,target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = load_point_cloud(\"/home/bot/dev/projects_data/kandovan/2023-07-14_162036_510311716_+0800_cycle_4_kandovan_depth_camera.pcd\")\n",
    "# target = load_point_cloud(\"/home/bot/dev/projects_data/gobekli/bottom\"_camera_data/1.2m/bottom_left/container_3_percipio_cloud_0.pcd\")\n",
    "# source.scale(0.001, center=False)\n",
    "\n",
    "center_point = np.array([0,0,2.15])\n",
    "min_bound = center_point - np.asarray([2, 2, 1.5])\n",
    "max_bound = center_point + np.asarray([2, 2, 0.3])\n",
    "\n",
    "cropbox = o3d.geometry.AxisAlignedBoundingBox(min_bound=min_bound, max_bound=max_bound)\n",
    "\n",
    "source = source.crop(cropbox)\n",
    "# target = target.crop(cropbox)\n",
    "\n",
    "o3d.visualization.draw_geometries([world_frame, source])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = load_point_cloud(\"/home/bot/dev/projects_data/gobekli/202308161248_calibration/2023-08-16_124514_769383667_+0100_cycle_56_percipio_tof_left.pcd\")\n",
    "target = load_point_cloud(\"/home/bot/dev/projects_data/gobekli/202308161248_calibration/2023-08-16_124514_970102406_+0100_cycle_56_percipio_tof_right.pcd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = load_point_cloud(\"/home/bot/dev/projects_data/kandovan/onsite/data/20231221_r2_right_color/2023-12-21_134046_398038789_+0800_cycle_2_kandovan_right_camera.pcd\")\n",
    "target = load_point_cloud(\"/home/bot/dev/projects_data/kandovan/onsite/data/20231221_r2_right_color/2023-12-21_134538_437162877_+0800_cycle_3_kandovan_right_camera.pcd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[118265, 113796, 19526, 111044]\n"
     ]
    }
   ],
   "source": [
    "source_ids = get_picked_indices(source)\n",
    "# source_ids = [36547, 3639, 1904, 32751, 96884, 57861, 51743, 93677, 43385, 9808, 5607, 39270]\n",
    "print(len(source_ids))\n",
    "print(source_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[118264, 112516, 20806, 110404]\n"
     ]
    }
   ],
   "source": [
    "target_ids = get_picked_indices(target)\n",
    "print(len(target_ids))\n",
    "print(target_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.99987881e-01  4.92282210e-03  6.50876567e-05 -5.08492599e-04]\n",
      " [-4.92291503e-03  9.99986736e-01  1.51438071e-03 -3.47590264e-04]\n",
      " [-5.76317665e-05 -1.51468278e-03  9.99998851e-01 -6.01671998e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "corr = np.zeros((len(source_ids), 2))\n",
    "corr[:, 0] = source_ids\n",
    "corr[:, 1] = target_ids\n",
    "\n",
    "p2p = o3d.registration.TransformationEstimationPointToPoint()\n",
    "trans_init = p2p.compute_transformation(\n",
    "    source, target, o3d.utility.Vector2iVector(corr)\n",
    ")\n",
    "print(trans_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "geometry::PointCloud with 614400 points."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_registration_result(source, target, trans_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.08492599e-04 -3.47590264e-04 -6.01671998e-03  9.99996683e-01\n",
      " -7.57268385e-04  3.06799575e-05 -2.46144244e-03]\n"
     ]
    }
   ],
   "source": [
    "pose = matrix2pose(trans_init)\n",
    "print(pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Matrix: \n",
      "[[ 9.99999996e-01 -6.82482665e-05  5.11866803e-05 -2.82088166e-04]\n",
      " [ 6.82501826e-05  9.99999997e-01 -3.74326677e-05 -4.97170563e-05]\n",
      " [-5.11841254e-05  3.74361611e-05  9.99999998e-01 -1.18076487e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reg_p2p = o3d.registration.registration_icp(\n",
    "    source,\n",
    "    target,\n",
    "    0.008,\n",
    "    trans_init,\n",
    "    o3d.registration.TransformationEstimationPointToPoint(),\n",
    ")\n",
    "\n",
    "transform = reg_p2p.transformation\n",
    "print(\"Transformation Matrix: \\n{}\\n\".format(transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cloud = draw_registration_result(source, target, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.14432480e-02  1.66433929e+00  1.90797654e-01  9.93973686e-01\n",
      "  1.03236776e-01  4.31258554e-04  3.68550377e-02]\n"
     ]
    }
   ],
   "source": [
    "pose = matrix2pose(transform)\n",
    "print(pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "84e04c4df81302457b834bddff417c10c4169c32f98dd4b4107ae96816994649"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
